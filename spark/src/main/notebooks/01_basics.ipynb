{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [API](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('Apache Spark test') \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"500\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.136.180.27:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Apache Spark test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10df095d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "[download data](https://github.com/databricks/Spark-The-Definitive-Guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"/Users/sg0218817/Downloads/Spark-The-Definitive-Guide-master/data/flight-data/parquet/2010-summary.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |1    |\n",
      "|United States    |Ireland            |264  |\n",
      "|United States    |India              |69   |\n",
      "|Egypt            |United States      |24   |\n",
      "|Equatorial Guinea|United States      |1    |\n",
      "|United States    |Singapore          |25   |\n",
      "|United States    |Grenada            |54   |\n",
      "|Costa Rica       |United States      |477  |\n",
      "|Senegal          |United States      |29   |\n",
      "|United States    |Marshall Islands   |44   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,LongType,true)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "|United States    |Singapore          |1    |\n",
      "|United States    |Grenada            |62   |\n",
      "|Costa Rica       |United States      |588  |\n",
      "|Senegal          |United States      |40   |\n",
      "|Moldova          |United States      |1    |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType\n",
    "\n",
    "my_schema = StructType([\n",
    "    StructField(\"DEST_COUNTRY_NAME\", StringType(), True),\n",
    "    StructField(\"ORIGIN_COUNTRY_NAME\", StringType(), True),\n",
    "    StructField(\"count\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read \\\n",
    "    .format(\"json\") \\\n",
    "    .schema(my_schema) \\\n",
    "    .load(\"/Users/sg0218817/Downloads/Spark-The-Definitive-Guide-master/data/flight-data/json/2015-summary.json\")\n",
    "\n",
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|exprMet|\n",
      "+-----------------+-------------------+-----+-------+\n",
      "|United States    |Romania            |15   |false  |\n",
      "|United States    |Croatia            |1    |false  |\n",
      "|United States    |Ireland            |344  |true   |\n",
      "|Egypt            |United States      |15   |false  |\n",
      "|United States    |India              |62   |true   |\n",
      "|United States    |Singapore          |1    |false  |\n",
      "|United States    |Grenada            |62   |true   |\n",
      "|Costa Rica       |United States      |588  |true   |\n",
      "|Senegal          |United States      |40   |true   |\n",
      "|Moldova          |United States      |1    |false  |\n",
      "+-----------------+-------------------+-----+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, expr, lit\n",
    "\n",
    "new_df = df.withColumn('exprMet', expr(\"(((count + 5) * 200) - 6) < 225 * count\"))\n",
    "new_df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME', 'count', 'exprMet']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.createOrReplaceTempView('df_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "my_row = Row('Poland', 'Norway', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Poland'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_row[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "from pyspark.sql import Row\n",
    "\n",
    "my_schema = StructType([\n",
    "    StructField(\"some\", StringType(), True),\n",
    "    StructField(\"col\", StringType(), True),\n",
    "    StructField(\"names\", LongType(), False)\n",
    "])\n",
    "\n",
    "my_row = Row(\"Hello\", None, 1)\n",
    "# my_df = spark.createDataFrame([my_row], my_schema)\n",
    "\n",
    "# my_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+-----------+\n",
      "|DEST_COUNTRY_NAME|(count * 10)|TwentyThree|\n",
      "+-----------------+------------+-----------+\n",
      "|    United States|         150|         23|\n",
      "|    United States|          10|         23|\n",
      "+-----------------+------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DEST_COUNTRY_NAME, count * 10, 23 AS TwentyThree FROM df_table\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+-----------+\n",
      "|DEST_COUNTRY_NAME|countTimes10|TwentyThree|\n",
      "+-----------------+------------+-----------+\n",
      "|    United States|         150|         23|\n",
      "|    United States|          10|         23|\n",
      "+-----------------+------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.select('DEST_COUNTRY_NAME', expr('count * 10 AS countTimes10'), lit(23).alias('TwentyThree')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+\n",
      "|  destination|c10|\n",
      "+-------------+---+\n",
      "|United States|150|\n",
      "|United States| 10|\n",
      "+-------------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.selectExpr('DEST_COUNTRY_NAME AS destination', 'count * 10 AS c10').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|exprMet|withinCountry|\n",
      "+-----------------+-------------------+-----+-------+-------------+\n",
      "|    United States|            Romania|   15|  false|        false|\n",
      "|    United States|            Croatia|    1|  false|        false|\n",
      "+-----------------+-------------------+-----+-------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.selectExpr('*', '(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) AS withinCountry').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------------------+\n",
      "| avg(count)|count(DISTINCT DEST_COUNTRY_NAME)|\n",
      "+-----------+---------------------------------+\n",
      "|1770.765625|                              132|\n",
      "+-----------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.selectExpr('AVG(count)', 'COUNT(DISTINCT(DEST_COUNTRY_NAME))').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add/Rename/Remove Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+-----+---------+-------------+\n",
      "|         dest| origin|count|numberOne|withinCountry|\n",
      "+-------------+-------+-----+---------+-------------+\n",
      "|United States|Romania|   15|        1|        false|\n",
      "|United States|Croatia|    1|        1|        false|\n",
      "+-------------+-------+-----+---------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.withColumn(\"numberOne\", lit(1)) \\\n",
    "    .withColumn(\"withinCountry\", expr('DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME')) \\\n",
    "    .withColumnRenamed(\"DEST_COUNTRY_NAME\", 'dest') \\\n",
    "    .withColumnRenamed(\"ORIGIN_COUNTRY_NAME\", 'origin') \\\n",
    "    .withColumn(\"count\", col('count').cast('integer')) \\\n",
    "    .drop('exprMet') \\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|exprMet|\n",
      "+-----------------+-------------------+-----+-------+\n",
      "|    United States|            Ireland|  344|   true|\n",
      "|       Costa Rica|      United States|  588|   true|\n",
      "+-----------------+-------------------+-----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.filter('count > 100').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|exprMet|\n",
      "+-----------------+-------------------+-----+-------+\n",
      "|    United States|            Ireland|  344|   true|\n",
      "|       Costa Rica|      United States|  588|   true|\n",
      "+-----------------+-------------------+-----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.filter(col('count') > 100).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|exprMet|\n",
      "+-----------------+-------------------+-----+-------+\n",
      "|    United States|            Ireland|  344|   true|\n",
      "|    United States|       Sint Maarten|  325|   true|\n",
      "+-----------------+-------------------+-----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df \\\n",
    "    .where(col('count') > 100) \\\n",
    "    .where(col('count') < 400) \\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.select('DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|  256|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT COUNT(DISTINCT(ORIGIN_COUNTRY_NAME, DEST_COUNTRY_NAME)) AS count FROM df_table').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+-------+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|exprMet|\n",
      "+--------------------+-------------------+-----+-------+\n",
      "|       United States|            Ireland|  344|   true|\n",
      "|             Bolivia|      United States|   30|  false|\n",
      "|    Marshall Islands|      United States|   42|   true|\n",
      "|       United States|             Angola|   13|  false|\n",
      "|       United States|             Cyprus|    1|  false|\n",
      "|       United States|              Samoa|   25|  false|\n",
      "|       United States|        The Bahamas|  986|   true|\n",
      "|              Cyprus|      United States|    1|  false|\n",
      "|Saint Kitts and N...|      United States|  139|   true|\n",
      "|    Papua New Guinea|      United States|    3|  false|\n",
      "|               Ghana|      United States|   18|  false|\n",
      "|              Poland|      United States|   32|  false|\n",
      "|            Bulgaria|      United States|    3|  false|\n",
      "+--------------------+-------------------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.sample(False, 0.05, 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = new_df.randomSplit([0.25, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 52 204\n"
     ]
    }
   ],
   "source": [
    "print(new_df.count(), dfs[0].count(), dfs[1].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|exprMet|\n",
      "+-----------------+-------------------+-----+-------+\n",
      "|         Anguilla|      United States|   41|   true|\n",
      "|            Aruba|      United States|  346|   true|\n",
      "+-----------------+-------------------+-----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs[0].union(dfs[1]).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|ORIGIN_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-------------------+-----------------+\n",
      "|             Angola|    United States|\n",
      "|           Anguilla|    United States|\n",
      "+-------------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.sort('ORIGIN_COUNTRY_NAME', col('DEST_COUNTRY_NAME').desc()) \\\n",
    "    .select('ORIGIN_COUNTRY_NAME', 'DEST_COUNTRY_NAME') \\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|exprMet|\n",
      "+-----------------+-------------------+-----+-------+\n",
      "|    United States|             Angola|   13|  false|\n",
      "|    United States|           Anguilla|   38|  false|\n",
      "+-----------------+-------------------+-----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.sortWithinPartitions('ORIGIN_COUNTRY_NAME').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repartition vs. Coalesce\n",
    "\n",
    "The repartition algorithm does a full shuffle of the data and creates equal sized partitions of data. coalesce combines existing partitions to avoid a full shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_df = new_df.repartition(5)\n",
    "rep_df.rdd.getNumPartitions()\n",
    "\n",
    "# rep_df.write.json('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_df = new_df.repartition('DEST_COUNTRY_NAME')\n",
    "rep_df.rdd.getNumPartitions()\n",
    "\n",
    "# rep_df.write.json('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coalesce_df = new_df.coalesce(2)\n",
    "coalesce_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.chain at 0x109c50c10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.collect()\n",
    "new_df.take(5)\n",
    "new_df.toLocalIterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('my_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count |\n",
      "+-----------------+-------------------+------+\n",
      "|United States    |United States      |370002|\n",
      "|United States    |Canada             |8483  |\n",
      "|Canada           |United States      |8399  |\n",
      "|United States    |Mexico             |7187  |\n",
      "|Mexico           |United States      |7140  |\n",
      "|United Kingdom   |United States      |2025  |\n",
      "|United States    |United Kingdom     |1970  |\n",
      "|Japan            |United States      |1548  |\n",
      "|United States    |Japan              |1496  |\n",
      "|Germany          |United States      |1468  |\n",
      "+-----------------+-------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count \n",
    "    FROM my_data\n",
    "    WHERE count > 100\n",
    "    SORT BY count DESC\n",
    "    \"\"\") \\\n",
    "    .show(10, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
