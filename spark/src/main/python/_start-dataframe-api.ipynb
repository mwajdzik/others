{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x10f9080b8>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.136.180.136:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "import os.path\n",
    "import shutil\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+-------------------+-----------+------------+\n|         event_date|location_id|temp_celcius|\n+-------------------+-----------+------------+\n|03/04/2019 19:48:06|       loc0|          29|\n|03/04/2019 19:53:06|       loc0|          27|\n|03/04/2019 19:58:06|       loc0|          28|\n|03/04/2019 20:03:06|       loc0|          30|\n|03/04/2019 20:08:06|       loc0|          27|\n|03/04/2019 20:13:06|       loc0|          27|\n|03/04/2019 20:18:06|       loc0|          27|\n|03/04/2019 20:23:06|       loc0|          29|\n|03/04/2019 20:28:06|       loc0|          32|\n|03/04/2019 20:33:06|       loc0|          35|\n+-------------------+-----------+------------+\nonly showing top 10 rows\n\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "500000"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "folder_path = '/Users/sg0218817/Downloads/Ex_Files_Spark_SQL_DataFrames/Exercise Files/Data'\n",
    "file_path = os.path.join(folder_path, 'location_temp.csv')\n",
    "df1 = spark.read.format('csv')\\\n",
    "    .option('header', 'true')\\\n",
    "    .load(file_path)\n",
    "\n",
    "df1.show(10)\n",
    "df1.count()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+\n|         event_date|server_id|cpu_utilization|free_memory|session_count|\n+-------------------+---------+---------------+-----------+-------------+\n|03/05/2019 08:06:14|      100|           0.57|       0.51|           47|\n|03/05/2019 08:11:14|      100|           0.47|       0.62|           43|\n|03/05/2019 08:16:14|      100|           0.56|       0.57|           62|\n|03/05/2019 08:21:14|      100|           0.57|       0.56|           50|\n|03/05/2019 08:26:14|      100|           0.35|       0.46|           43|\n|03/05/2019 08:31:14|      100|           0.41|       0.58|           48|\n|03/05/2019 08:36:14|      100|           0.57|       0.35|           58|\n|03/05/2019 08:41:14|      100|           0.41|        0.4|           58|\n|03/05/2019 08:46:14|      100|           0.53|       0.35|           62|\n|03/05/2019 08:51:14|      100|           0.51|        0.6|           45|\n+-------------------+---------+---------------+-----------+-------------+\nonly showing top 10 rows\n\nroot\n |-- event_date: string (nullable = true)\n |-- server_id: integer (nullable = true)\n |-- cpu_utilization: double (nullable = true)\n |-- free_memory: double (nullable = true)\n |-- session_count: integer (nullable = true)\n\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "500000"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "file_path = os.path.join(folder_path, 'utilization.csv')\n",
    "df2 = spark.read.format('csv')\\\n",
    "    .option('header', 'false')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load(file_path)\n",
    "\n",
    "df2 = df2.withColumnRenamed('_c0', 'event_date') \\\n",
    "    .withColumnRenamed('_c1', 'server_id') \\\n",
    "    .withColumnRenamed('_c2', 'cpu_utilization') \\\n",
    "    .withColumnRenamed('_c3', 'free_memory') \\\n",
    "    .withColumnRenamed('_c4', 'session_count')\n",
    "\n",
    "df2.show(10)\n",
    "df2.printSchema()\n",
    "df2.count()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "file_path = os.path.join(folder_path, 'utilization')\n",
    "\n",
    "shutil.rmtree(file_path)\n",
    "\n",
    "df2.write.format('json')\\\n",
    "    .save(file_path)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n|cpu_utilization|         event_date|free_memory|server_id|session_count|\n+---------------+-------------------+-----------+---------+-------------+\n|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n+---------------+-------------------+-----------+---------+-------------+\nonly showing top 10 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "file_path = os.path.join(folder_path, 'utilization', '*.json')\n",
    "df3 = spark.read.format('json')\\\n",
    "    .load(file_path)\n",
    "\n",
    "df3.show(10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['cpu_utilization', 'event_date', 'free_memory', 'server_id', 'session_count']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "df3.columns\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n|cpu_utilization|         event_date|free_memory|server_id|session_count|\n+---------------+-------------------+-----------+---------+-------------+\n|           0.23|03/22/2019 10:01:25|       0.66|      106|           65|\n|           0.23|03/31/2019 04:16:47|       0.44|      119|           67|\n|           0.23|03/13/2019 19:21:47|        0.5|      119|           65|\n|           0.24|04/05/2019 15:46:56|       0.39|      124|           66|\n|           0.24|03/24/2019 20:22:22|       0.59|      138|           67|\n|           0.24|03/07/2019 12:01:46|       0.75|      119|           64|\n|           0.24|04/03/2019 12:42:23|       0.72|      138|           68|\n|           0.24|03/11/2019 05:56:47|       0.46|      119|           63|\n|           0.25|04/06/2019 00:01:26|       0.39|      106|           61|\n|           0.25|03/24/2019 18:07:22|       0.39|      138|           65|\n+---------------+-------------------+-----------+---------+-------------+\nonly showing top 10 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df4 = df3.sample(False, fraction=0.05) \\\n",
    "    .filter(df3['session_count'] > 60) \\\n",
    "    .sort('cpu_utilization')\n",
    "\n",
    "df4.show(10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+-----------+-----------------+\n|location_id|avg(temp_celcius)|\n+-----------+-----------------+\n|       loc0|           29.176|\n|       loc1|           28.246|\n|      loc10|           25.337|\n|     loc100|           27.297|\n|     loc101|           25.317|\n|     loc102|           30.327|\n|     loc103|           25.341|\n|     loc104|           26.204|\n|     loc105|           26.217|\n|     loc106|           27.201|\n+-----------+-----------------+\nonly showing top 10 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df5 = df1.groupBy('location_id') \\\n",
    "    .agg({'temp_celcius': 'mean'}) \\\n",
    "    .orderBy('location_id')\n",
    "\n",
    "df5.show(10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "/Users/sg0218817/Private/IT/others/spark/src/main/python\r\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "! pwd\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "_start-dataframe-api.ipynb parquet-connector.ipynb\r\n_start-sql.ipynb           start-pi-calculation.ipynb\r\nmongo-connector.ipynb\r\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "! ls\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}