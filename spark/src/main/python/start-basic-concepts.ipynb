{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x10fbd6668>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://172.19.36.12:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# http://localhost:4040\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.shuffle.partitions', '5')\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+--------------------+-------------------+-----+\n|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+--------------------+-------------------+-----+\n|       United States|            Romania|   15|\n|       United States|            Croatia|    1|\n|       United States|            Ireland|  344|\n|               Egypt|      United States|   15|\n|       United States|              India|   62|\n|       United States|          Singapore|    1|\n|       United States|            Grenada|   62|\n|          Costa Rica|      United States|  588|\n|             Senegal|      United States|   40|\n|             Moldova|      United States|    1|\n|       United States|       Sint Maarten|  325|\n|       United States|   Marshall Islands|   39|\n|              Guyana|      United States|   64|\n|               Malta|      United States|    1|\n|            Anguilla|      United States|   41|\n|             Bolivia|      United States|   30|\n|       United States|           Paraguay|    6|\n|             Algeria|      United States|    4|\n|Turks and Caicos ...|      United States|  230|\n|       United States|          Gibraltar|    1|\n+--------------------+-------------------+-----+\nonly showing top 20 rows\n\nroot\n |-- DEST_COUNTRY_NAME: string (nullable = true)\n |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n |-- count: integer (nullable = true)\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df = spark.read.format('csv')\\\n",
    "    .option('header', 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('../data/flight-data/2015-summary.csv')\n",
    "\n",
    "df.show()\n",
    "df.printSchema()\n"
   ],
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "== Physical Plan ==\n*(2) Sort [count#12 DESC NULLS LAST], true, 0\n+- Exchange rangepartitioning(count#12 DESC NULLS LAST, 5)\n   +- *(1) Project [ORIGIN_COUNTRY_NAME#11, DEST_COUNTRY_NAME#10, count#12]\n      +- *(1) Filter (isnotnull(count#12) && (count#12 > 10))\n         +- *(1) FileScan csv [DEST_COUNTRY_NAME#10,ORIGIN_COUNTRY_NAME#11,count#12] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/sg0218817/Private/IT/others/spark/src/main/data/flight-data/2015-su..., PartitionFilters: [], PushedFilters: [IsNotNull(count), GreaterThan(count,10)], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:int>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df.filter('count > 10')\\\n",
    "    .select('ORIGIN_COUNTRY_NAME', 'DEST_COUNTRY_NAME', 'count') \\\n",
    "    .sort('count', ascending=False)\\\n",
    "    .explain()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+-------------------+------------------+------+\n|ORIGIN_COUNTRY_NAME| DEST_COUNTRY_NAME| count|\n+-------------------+------------------+------+\n|      United States|     United States|370002|\n|             Canada|     United States|  8483|\n|      United States|            Canada|  8399|\n|             Mexico|     United States|  7187|\n|      United States|            Mexico|  7140|\n|      United States|    United Kingdom|  2025|\n|     United Kingdom|     United States|  1970|\n|      United States|             Japan|  1548|\n|              Japan|     United States|  1496|\n|      United States|           Germany|  1468|\n| Dominican Republic|     United States|  1420|\n|      United States|Dominican Republic|  1353|\n|            Germany|     United States|  1336|\n|      United States|       South Korea|  1048|\n|        The Bahamas|     United States|   986|\n|      United States|       The Bahamas|   955|\n|             France|     United States|   952|\n|      United States|            France|   935|\n|              China|     United States|   920|\n|      United States|          Colombia|   873|\n+-------------------+------------------+------+\nonly showing top 20 rows\n\n== Physical Plan ==\n*(2) Sort [count#12 DESC NULLS LAST], true, 0\n+- Exchange rangepartitioning(count#12 DESC NULLS LAST, 5)\n   +- *(1) Project [ORIGIN_COUNTRY_NAME#11, DEST_COUNTRY_NAME#10, count#12]\n      +- *(1) Filter (isnotnull(count#12) && (count#12 > 10))\n         +- *(1) FileScan csv [DEST_COUNTRY_NAME#10,ORIGIN_COUNTRY_NAME#11,count#12] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/sg0218817/Private/IT/others/spark/src/main/data/flight-data/2015-su..., PartitionFilters: [], PushedFilters: [IsNotNull(count), GreaterThan(count,10)], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:int>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df1 = df.filter('count > 10')\\\n",
    "    .select('ORIGIN_COUNTRY_NAME', 'DEST_COUNTRY_NAME', 'count') \\\n",
    "    .sort('count', ascending=False)\n",
    "\n",
    "df1.show()\n",
    "df1.explain()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+-------------------+------------------+------+\n|ORIGIN_COUNTRY_NAME| DEST_COUNTRY_NAME| count|\n+-------------------+------------------+------+\n|      United States|     United States|370002|\n|             Canada|     United States|  8483|\n|      United States|            Canada|  8399|\n|             Mexico|     United States|  7187|\n|      United States|            Mexico|  7140|\n|      United States|    United Kingdom|  2025|\n|     United Kingdom|     United States|  1970|\n|      United States|             Japan|  1548|\n|              Japan|     United States|  1496|\n|      United States|           Germany|  1468|\n| Dominican Republic|     United States|  1420|\n|      United States|Dominican Republic|  1353|\n|            Germany|     United States|  1336|\n|      United States|       South Korea|  1048|\n|        The Bahamas|     United States|   986|\n|      United States|       The Bahamas|   955|\n|             France|     United States|   952|\n|      United States|            France|   935|\n|              China|     United States|   920|\n|      United States|          Colombia|   873|\n+-------------------+------------------+------+\nonly showing top 20 rows\n\n== Physical Plan ==\n*(2) Sort [count#12 DESC NULLS LAST], true, 0\n+- Exchange rangepartitioning(count#12 DESC NULLS LAST, 5)\n   +- *(1) Project [ORIGIN_COUNTRY_NAME#11, DEST_COUNTRY_NAME#10, count#12]\n      +- *(1) Filter (isnotnull(count#12) && (count#12 > 10))\n         +- *(1) FileScan csv [DEST_COUNTRY_NAME#10,ORIGIN_COUNTRY_NAME#11,count#12] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/sg0218817/Private/IT/others/spark/src/main/data/flight-data/2015-su..., PartitionFilters: [], PushedFilters: [IsNotNull(count), GreaterThan(count,10)], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:int>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df.createOrReplaceTempView('flight_data')\n",
    "\n",
    "df2 = spark.sql('SELECT ORIGIN_COUNTRY_NAME, DEST_COUNTRY_NAME, count '\n",
    "               'FROM flight_data '\n",
    "               'WHERE count > 10 '\n",
    "               'ORDER BY count DESC')\n",
    "\n",
    "df2.show()\n",
    "df2.explain()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+-----------------+-----------------+\n|DEST_COUNTRY_NAME|destination_total|\n+-----------------+-----------------+\n|    United States|           411352|\n|           Canada|             8399|\n|           Mexico|             7140|\n|   United Kingdom|             2025|\n|            Japan|             1548|\n+-----------------+-----------------+\n\n== Physical Plan ==\nTakeOrderedAndProject(limit=5, orderBy=[destination_total#71L DESC NULLS LAST], output=[DEST_COUNTRY_NAME#10,destination_total#71L])\n+- *(2) HashAggregate(keys=[DEST_COUNTRY_NAME#10], functions=[sum(cast(count#12 as bigint))])\n   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#10, 5)\n      +- *(1) HashAggregate(keys=[DEST_COUNTRY_NAME#10], functions=[partial_sum(cast(count#12 as bigint))])\n         +- *(1) FileScan csv [DEST_COUNTRY_NAME#10,count#12] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/sg0218817/Private/IT/others/spark/src/main/data/flight-data/2015-su..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,count:int>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df3 = df.groupBy('DEST_COUNTRY_NAME') \\\n",
    "    .sum('count')\\\n",
    "    .withColumnRenamed('sum(count)', 'destination_total')\\\n",
    "    .sort(desc('destination_total'))\\\n",
    "    .limit(5)\n",
    "\n",
    "df3.show()\n",
    "df3.explain()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+-----------------+-----------------+\n|DEST_COUNTRY_NAME|destination_total|\n+-----------------+-----------------+\n|    United States|           411352|\n|           Canada|             8399|\n|           Mexico|             7140|\n|   United Kingdom|             2025|\n|            Japan|             1548|\n+-----------------+-----------------+\n\n== Physical Plan ==\nTakeOrderedAndProject(limit=5, orderBy=[destination_total#85L DESC NULLS LAST], output=[DEST_COUNTRY_NAME#10,destination_total#85L])\n+- *(2) HashAggregate(keys=[DEST_COUNTRY_NAME#10], functions=[sum(cast(count#12 as bigint))])\n   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#10, 5)\n      +- *(1) HashAggregate(keys=[DEST_COUNTRY_NAME#10], functions=[partial_sum(cast(count#12 as bigint))])\n         +- *(1) FileScan csv [DEST_COUNTRY_NAME#10,count#12] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/sg0218817/Private/IT/others/spark/src/main/data/flight-data/2015-su..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,count:int>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df4 = spark.sql('SELECT DEST_COUNTRY_NAME, SUM(count) AS destination_total '\n",
    "                'FROM flight_data '\n",
    "                'GROUP BY DEST_COUNTRY_NAME '\n",
    "                'ORDER BY destination_total DESC '\n",
    "                'LIMIT 5')\n",
    "\n",
    "df4.show()\n",
    "df4.explain()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-9b5e08a5",
   "language": "python",
   "display_name": "PyCharm (spark)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}